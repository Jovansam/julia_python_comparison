{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No, Python is Not Too Slow for Computational Economics\n",
    "\n",
    "### John Stachurski\n",
    "\n",
    "#### Australian National University\n",
    "\n",
    "Acknowledgements: Thanks to anonymous friends for helpful comments\n",
    "\n",
    "Date: September 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In [this paper](https://github.com/jstac/julia_python_comparison/blob/master/Update_March_23_2018.pdf), S. Boragan Aruoba and Jesus Fernandez-Villaverde (AFV) study the relative speed of a range of programming lanugages by testing them on a value function iteration routine.  In the abstract they state:\n",
    "\n",
    "**\"The central conclusions of our original paper remain unaltered: C++ is the fastest alternative, Julia offers a great balance of speed and ease of use, and Python is too slow.\"**\n",
    "\n",
    "Even the authors' own findings do not support this conclusion.  In their table 1, Python combined with its scientific libraries is actually reported as slightly faster than Julia (2.31 seconds for Python vs 2.35 for Julia).\n",
    "\n",
    "We rerun the code below and find a similar outcome: The Python code runs in around 3.5 seconds, compared to Julia's 4.5.  The execution environment is \n",
    "\n",
    "```\n",
    "Architecture:        x86_64\n",
    "CPU op-mode(s):      32-bit, 64-bit\n",
    "Byte Order:          Little Endian\n",
    "CPU(s):              4\n",
    "On-line CPU(s) list: 0-3\n",
    "Thread(s) per core:  2\n",
    "Core(s) per socket:  2\n",
    "Socket(s):           1\n",
    "NUMA node(s):        1\n",
    "Vendor ID:           GenuineIntel\n",
    "CPU family:          6\n",
    "Model:               142\n",
    "Model name:          Intel(R) Core(TM) i5-7300U CPU @ 2.60GHz\n",
    "```\n",
    "\n",
    "We are using the latest version of each language and scientific ecosystem at the time of writing: Julia 1.0 and Anaconda Python 5.2.\n",
    "\n",
    "Of course, we are comparing only Julia vs Python plus its scientific libraries (as opposed to Julia vs pure Python), since no scientist would consider foregoing the scientific libraries when implementing computationally intensive algorithms in Python.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Python is massively popular for both general purpose and scientific computing (see, e.g., [this ranking](https://spectrum.ieee.org/static/interactive-the-top-programming-languages-2018)).  Its popularity is partly due to (and partly caused by) the huge range of third party libraries.  Within the scientific domain, these libraries include high quality array processing software and a powerful JIT compiler.  \n",
    "\n",
    "2. Python's primary scientific JIT compiler (Numba) and Julia's JIT compiler are built on the same architecture (LLVM).  Similar execution times are to be expected.  From this perspective it is surprising that the Python code runs faster on this machine.  Other users are likely to get slightly different relative run times.\n",
    "\n",
    "3. AFV do not display any profiling of their codes in the different languages. No memory footprint, no flop rates, etc. are shown. This matters because memory access patterns can always be optimized, especially in small problems as treated here.  One would have to take into account all the individual features of the programming languages to make a fair comparison. (Most likely there would be no surprise, as their performance behavior is known.)  A useful refernence is: S. Goedecker and A. Hoisie. Performance Optimization of Numerically Intensive Codes (SIAM), 2001. ISBN 978-0898714845. \n",
    "\n",
    "4. As an aside, the author thinks Julia is a great project and hopes that it succeeds.  Python wouldn't be where it is now without the flow of ideas (and competitive pressure) from Julia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is exactly as in the [GitHub](https://github.com/jesusfv/Comparison-Programming-Languages-Economics) repo, except for the following changes, consistent comments made in the 2018 paper. \n",
    "\n",
    "1. Doubled the length of the capital grid.\n",
    "2. Convergence tolerance is 1e-8.\n",
    "3. Print out status after every 20 iterations.\n",
    "4. Changed print statements to print functions (Python 3 compliance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "from numba import njit, prange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "β = 0.95\n",
    "α = 1/3\n",
    "A = np.array([0.9792, 0.9896, 1.0000, 1.0106, 1.0212])  # Productivity\n",
    "\n",
    "# Transition matrix\n",
    "π = np.array([[0.9727, 0.0273, 0.0000, 0.0000, 0.0000],\n",
    "              [0.0041, 0.9806, 0.0153, 0.0000, 0.0000],\n",
    "              [0.0000, 0.0082, 0.9837, 0.0082, 0.0000],\n",
    "              [0.0000, 0.0000, 0.0153, 0.9806, 0.0041],\n",
    "              [0.0000, 0.0000, 0.0000, 0.0273, 0.9727]])\n",
    "\n",
    "# Steady state values\n",
    "\n",
    "k_star = (α * β)**(1 / (1 - α))  # Steady state capital\n",
    "y_star = k_star**α               # Steady state output\n",
    "c_star = y_star - k_star         # Steady state consumption\n",
    "\n",
    "# Set up capital grid\n",
    "n = 35640                        # Number of grid points\n",
    "k_grid = np.linspace(0.5 * k_star, 1.5 * k_star, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True)\n",
    "def innerloop(k_grid, v, A, π, β):\n",
    "    \n",
    "    E_v = v @ π.T                    # Expected value function\n",
    "    y_grid = np.outer(k_grid**α, A)  # Output grid\n",
    "    \n",
    "    v_new = np.empty_like(y_grid)\n",
    "    σ = np.empty_like(y_grid)\n",
    "    k_next = 0\n",
    "    \n",
    "    for a in prange(len(A)):\n",
    "        \n",
    "        for i in prange(len(k_grid)):\n",
    "\n",
    "            v_max = -1e5\n",
    "            k_prime = k_grid[0]\n",
    "\n",
    "            for j in prange(k_next, len(k_grid)):  \n",
    "                y = y_grid[i, a]\n",
    "                k = k_grid[j]\n",
    "                c = y - k\n",
    "                v_temp = (1 - β) * np.log(c) + β * E_v[j, a];\n",
    "\n",
    "                if v_temp > v_max:\n",
    "                    v_max = v_temp\n",
    "                    k_prime = k_grid[j]\n",
    "                    k_next = j\n",
    "                else:\n",
    "                    break \n",
    "\n",
    "            v_new[i, a] = v_max\n",
    "            σ[i, a] = k_prime\n",
    "\n",
    "    return v_new, σ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_model(k_grid, \n",
    "                A, \n",
    "                π,\n",
    "                α=1/3, \n",
    "                β=0.95,\n",
    "                tol=1e-8,\n",
    "                maxiter=1000):\n",
    "\n",
    "    # Initialize values\n",
    "    diff = 1e3\n",
    "    i = 0\n",
    "    v = np.zeros((len(k_grid), len(A)))\n",
    "\n",
    "    while diff > tol and i < maxiter:       \n",
    "            \n",
    "        # Update value and policy functions for given productivity\n",
    "        v_new, σ = innerloop(k_grid, v, A, π, β)\n",
    "\n",
    "        diff = np.abs(v_new - v).max()\n",
    "        v = v_new\n",
    "\n",
    "        i += 1\n",
    "        if(i % 20 == 0 or i == 1):\n",
    "            print(f\"Iteration {i}: diff = {diff}\")\n",
    "            \n",
    "    print(f'Coverged in {i} iterations')\n",
    "            \n",
    "    return v_new, σ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: diff = 0.05274159340733661\n",
      "Iteration 20: diff = 0.018703461659313803\n",
      "Iteration 40: diff = 0.006668550348659208\n",
      "Iteration 60: diff = 0.0023813230210369962\n",
      "Iteration 80: diff = 0.0008513486462362607\n",
      "Iteration 100: diff = 0.00030462866646285836\n"
     ]
    }
   ],
   "source": [
    "%time solve_model(k_grid, A, π)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another claim of the paper is that \"Julia benefits a lot from a mild investment on optimization and makes it easier to compare with `Numba` and `Cython`, which require extra work as well with respect to basic Python\". The evidence they provide actually supports the opposite claim. After adapting their original code to Python 3, it turns out that only two lines need to be added (and a few of their inconsistencies deleted) to get `Numba` to run: `from numba import jit` and `@njit`. Not only is this extremely easy, but it is also much less work than AVF put into trying to optimize their Julia code, which can be partially observed by looking at the history of the file [here](https://github.com/jesusfv/Comparison-Programming-Languages-Economics/commits/master/RBC_Julia.jl). For timing purposes, we also remove the print statements, and add a warm-up period. We run the new code in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Julia version\n",
    "\n",
    "To run the Julia code you will need to download it from [here](https://github.com/jstac/julia_python_comparison) and place it in the present working directory. We remove the print statements and add a warm-up iteration to be consistent with the Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First run (warm-up): \n",
      "  3.992546 seconds (2.62 M allocations: 1.337 GiB, 7.72% gc time)\n",
      "Second run: \n",
      "  2.335853 seconds (1.84 k allocations: 1.211 GiB, 3.89% gc time)\n"
     ]
    }
   ],
   "source": [
    "!julia RBC_Julia.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not the only ones who made similar observations. Other researchers report that Python is faster than Julia [here](https://discourse.julialang.org/t/a-comparison-of-programming-languages-in-economics/8966/19)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
